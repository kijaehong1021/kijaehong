# ğŸ‘‹ Kijae Hong (í™ê¸°ì¬)

## Introduction

I am a Researcher at Ceres Technologies and a Ph.D. graduate in Computer Science from POSTECH, specializing in the convergence of Database systems and Artificial Intelligence. My core expertise lies in GPU acceleration, Graph Data Analysis, and LLM serving optimization.

í¬í•­ê³µëŒ€(POSTECH) ì»´í“¨í„°ê³µí•™ê³¼ ë°•ì‚¬ ì¶œì‹ ìœ¼ë¡œ, í˜„ì¬ ì„¸ë ˆìŠ¤í…Œí¬ë†€ë¡œì§€ìŠ¤(Ceres Technologies)ì—ì„œ **ë°ì´í„°ë² ì´ìŠ¤ì™€ AI ê¸°ìˆ ì˜ ê²°í•©(DB+AI)** ì„ ì—°êµ¬í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì£¼ë ¥ ë¶„ì•¼ëŠ” GPU ê°€ì† ê¸°ë°˜ì˜ ë°ì´í„° ì²˜ë¦¬, ê·¸ë˜í”„ ë°ì´í„° ë¶„ì„, ê·¸ë¦¬ê³  LLM ì„œë¹™ ë° ì¶”ë¡  ìµœì í™”ì…ë‹ˆë‹¤.

Currently, I focus on building a high-frequency-trading system, building efficient RAG systems, and optimizing LLM inference (vLLM, caching, scheduling). With a strong academic foundation demonstrated by publications in top-tier conferences like VLDB and SIGMOD, and a portfolio of patents in query processing and AI, I am dedicated to developing scalable, high-speed architectures for next-generation data processing.


í˜„ì¬ëŠ” ì´ˆê³ ë¹ˆë„ ë§¤ë§¤(High-Frequency Trading) ì‹œìŠ¤í…œ ê°œë°œ, vLLM ë° ì¿ ë²„ë„¤í‹°ìŠ¤(Kubernetes)ë¥¼ í™œìš©í•œ ê³ ì„±ëŠ¥ RAG ì‹œìŠ¤í…œ êµ¬ì¶•ê³¼ LLM ë¯¸ì„¸ì¡°ì •(Fine-tuning) ì—…ë¬´ë¥¼ ìˆ˜í–‰í•˜ê³  ìˆìŠµë‹ˆë‹¤. VLDB, SIGMOD ë“± ì„¸ê³„ ìµœê³  ìˆ˜ì¤€ì˜ í•™íšŒì— ë‹¤ìˆ˜ì˜ ë…¼ë¬¸ì„ ê²Œì¬í•˜ê³  ê´€ë ¨ íŠ¹í—ˆë¥¼ ë³´ìœ í•˜ëŠ” ë“±, ì´ë¡ ì  ê¹Šì´ì™€ ì‹¤ë¬´ì  êµ¬í˜„ ëŠ¥ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ ëŒ€ê·œëª¨ ë°ì´í„° ì²˜ë¦¬ ì‹œìŠ¤í…œì˜ í˜ì‹ ì„ ì¶”êµ¬í•©ë‹ˆë‹¤.

---
## ğŸ“§ Contact

- Email: kijaehong1021@gmail.com
- GitHub: [@kijaehong](https://github.com/kijaehong)
- LinkedIn: [@Ki-jae Hong](https://www.linkedin.com/in/ki-jae-hong-5643b730a/)
- Location: Seoul, South Korea
- Others: [Google Scholar](https://scholar.google.com/citations?user=QHGq7GIAAAAJ&hl=ko), [DBLP](https://dblp.org/pid/266/5820.html)

---
## ğŸ”¬ Ongoing Projects

### [Maximizing LLM Caching](https://github.com/kijaehong1021/LLMCachingBoost)

With the rapid advancement of LLMs, there are emerging attempts to expand the scope of data analysis in databases by leveraging LLMs. I'm conducting research on optimizing LLM caching for this purpose.

LLMì˜ ì—„ì²­ë‚œ ë°œì „ ì†ë„ì— ë”°ë¼, LLMì„ í™œìš©í•˜ì—¬ ë°ì´í„°ë² ì´ìŠ¤ì˜ ë°ì´í„° ë¶„ì„ ê°€ëŠ¥ ë²”ìœ„ë¥¼ ë” ë„“íˆë ¤ëŠ” ì‹œë„ë“¤ì´ ìƒê²¨ë‚˜ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ë¦¬ê³  ì €ëŠ” ì´ëŸ¬í•œ í™˜ê²½ì—ì„œ, LLM ìºì‹± í…Œí¬ë‹‰ë“¤ì˜ íš¨ê³¼ë¥¼ ê·¹ëŒ€í™”í•˜ê¸° ìœ„í•´ ì–´ë–¤ ë°©ë²•ì´ ìˆì„ì§€ íƒêµ¬í•´ë³´ê³  ìˆìŠµë‹ˆë‹¤.

### [Optimizing Semantic Operators in a Query Plan](https://github.com/kijaehong1021/SemanticOptimizerOptimizer)

To broaden the analytical capabilities of databases, recent research is incorporating LLMs into database operators to 1) check specific conditions or 2) extract new attributes from records. However, since LLM inference is a highly costly operation, finding ways to minimize this overhead is essential, and this is a topic I am currently exploring with great interest.

LLMì„ í™œìš©í•´ì„œ ë°ì´í„°ë² ì´ìŠ¤ì˜ ë¶„ì„ ê°€ëŠ¥ ë²”ìœ„ë¥¼ ë„“íˆê¸° ìœ„í•´, ìµœê·¼ ì—°êµ¬ë“¤ì€ databaseì˜ ì—°ì‚°ìë“¤ì´ LLM inferenceë¥¼ í†µí•´ recordì— ëŒ€í•œ 1) conditionì„ ì²´í¬í•˜ê±°ë‚˜, 2)ìƒˆë¡œìš´ attributeë¥¼ ì¶”ì¶œí•  ìˆ˜ ìˆë„ë¡ í™•ì¥í•˜ê³  ìˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ, LLM inferenceëŠ” ë§¤ìš° ë¹„ì‹¼ ì—°ì‚°ì´ê¸° ë•Œë¬¸ì— ì´ë¥¼ ìµœëŒ€í•œ ì¤„ì´ëŠ” ë°©ì•ˆì´ í•„ìš”í•˜ë©°, ì´ëŠ” ì œê°€ ìš”ì¦˜ í¥ë¯¸ë¡­ê²Œ íƒêµ¬í•˜ê³  ìˆëŠ” ì£¼ì œì…ë‹ˆë‹¤.

---

## ğŸ’¼ Previous Projects
<!-- 
### T-R3X 
TBD

### RAG-based Customer Support System for í˜„ëŒ€í™ˆì‡¼í•‘
TBD

### Knowledge Management System
TBD -->

### SLM-based Operator of RAG

Amid the surging demand for RAG systems, I developed an SLM-based operator designed to execute core system functions with low latency and cost efficiency, a project supported by the Ministry of SMEs and Startups. I established a robust operational infrastructure by deploying vLLM-based inference services on Kubernetes and implementing auto-scaling tailored to workload fluctuations. Through this process, I acquired in-depth expertise in LLM fine-tuning techniques as well as serving infrastructure utilizing vLLM and Kubernetes.

RAG ì‹œìŠ¤í…œì˜ ìˆ˜ìš”ê°€ ê¸‰ì¦í•¨ì— ë”°ë¼, ì‹œìŠ¤í…œì˜ í•µì‹¬ ê¸°ëŠ¥ì„ ì €ë¹„ìš©Â·ì €ì§€ì—°ìœ¼ë¡œ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” Small Language Model(SLM) ê¸°ë°˜ì˜ operatorë“¤ì„ ì¤‘ì†Œë²¤ì²˜ê¸°ì—…ë¶€ ì§€ì›í•˜ì— ê°œë°œí–ˆìŠµë‹ˆë‹¤. ë˜í•œ, vLLMì„ í™œìš©í•œ ì¶”ë¡  ì„œë¹„ìŠ¤ë¥¼ ì¿ ë²„ë„¤í‹°ìŠ¤ í™˜ê²½ì— êµ¬ì¶•í•˜ê³  ì›Œí¬ë¡œë“œì— ë”°ë¥¸ ì˜¤í†  ìŠ¤ì¼€ì¼ë§ì„ êµ¬í˜„í•˜ëŠ” ë“± ì•ˆì •ì ì¸ ìš´ì˜ ì¸í”„ë¼ë¥¼ ë§ˆë ¨í–ˆìŠµë‹ˆë‹¤. ì´ ê³¼ì •ì„ í†µí•´ LLM íŒŒì¸íŠœë‹ ê¸°ìˆ ì€ ë¬¼ë¡ , vLLM ë° ì¿ ë²„ë„¤í‹°ìŠ¤ë¥¼ í™œìš©í•œ ì„œë¹™ ì¸í”„ë¼ êµ¬ì¶•ì— ëŒ€í•œ ì‹¬ë„ ìˆëŠ” ì—­ëŸ‰ì„ í™•ë³´í–ˆìŠµë‹ˆë‹¤. 


### High Frequency Trading

At Ceres Technologies, I developed a distributed and parallel processing system capable of collecting tens of thousands of market events per second to perform real-time price prediction and automated trading. This project, supported by the Ministry of SMEs and Startups, was engineered to handle high-volume traffic with stability and has been successfully deployed and operated for multiple client companies.

ì„¸ë ˆìŠ¤ í…Œí¬ë†€ë¡œì§€ìŠ¤ì—ì„œ ì´ˆë‹¹ ìˆ˜ë§Œ ê±´ì— ë‹¬í•˜ëŠ” ì‹œì¥ ì´ë²¤íŠ¸ë¥¼ ìˆ˜ì§‘í•˜ê³ , ì‹¤ì‹œê°„ ê°€ê²© ì˜ˆì¸¡ ë° ë§¤ë§¤ë¥¼ ìë™ìœ¼ë¡œ ìˆ˜í–‰í•˜ëŠ” ë¶„ì‚°/ë³‘ë ¬ ì²˜ë¦¬ ì‹œìŠ¤í…œì„ ì¤‘ì†Œê¸°ì—…ë²¤ì²˜ë¶€ ì§€ì›í•˜ì— ê°œë°œí–ˆìŠµë‹ˆë‹¤. ëŒ€ê·œëª¨ íŠ¸ë˜í”½ì„ ì•ˆì •ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ë„ë¡ ì„¤ê³„ëœ ì´ ì‹œìŠ¤í…œì€ ë‹¤ìˆ˜ì˜ ê³ ê°ì‚¬ì— ì„±ê³µì ìœ¼ë¡œ ë„ì…ë˜ì–´ ìš´ìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤.


### [GPU-accelerated Relational Query Execution Engine](https://www.vldb.org/pvldb/vol18/p426-han.pdf)

During my doctoral studies, I conducted research on accelerating relational data analysis queries using GPUs, a distinct achievement that led to a publication in VLDB, a top-tier database conference. This research focused on resolving load imbalance issuesâ€”specifically inter-warp and intra-warp thread divergenceâ€”during parallel processing, ultimately achieving a query processing performance approximately 379 times faster than competing technologies. Through this research, I gained a profound understanding of GPU architecture and mastered various optimization techniques within the CUDA environment.

ë°•ì‚¬ ê³¼ì • ì¤‘ GPUë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê´€ê³„í˜• ë°ì´í„° ë¶„ì„ ì§ˆì˜ë¥¼ ê°€ì†í™”í•˜ëŠ” ì—°êµ¬ë¥¼ ìˆ˜í–‰í•˜ì˜€ìœ¼ë©°, ê·¸ ì„±ê³¼ë¥¼ ì¸ì •ë°›ì•„ ë°ì´í„°ë² ì´ìŠ¤ ë¶„ì•¼ ìµœê³  ê¶Œìœ„ í•™íšŒì¸ VLDBì— ë…¼ë¬¸ì„ ê²Œì¬í•˜ì˜€ìŠµë‹ˆë‹¤. ë³¸ ì—°êµ¬ëŠ” ë³‘ë ¬ ì²˜ë¦¬ ê³¼ì •ì—ì„œ ë°œìƒí•˜ëŠ” ì›Œí”„ ê°„, ê·¸ë¦¬ê³  ì›Œí”„ ë‚´ ìŠ¤ë ˆë“œ ê°„ì˜ ë¶€í•˜ ë¶ˆê· í˜•(Load Imbalance) ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ë° ì§‘ì¤‘í•˜ì˜€ìœ¼ë©°, ì´ë¥¼ í†µí•´ ê²½ìŸ ê¸°ìˆ  ëŒ€ë¹„ ì•½ 379ë°° ë¹ ë¥¸ ì§ˆì˜ ì²˜ë¦¬ ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ëŠ” ë° ì„±ê³µí–ˆìŠµë‹ˆë‹¤. ì´ ê³¼ì •ì„ í†µí•´ GPU ì•„í‚¤í…ì²˜ì— ëŒ€í•œ ê¹Šì€ ì´í•´ë¥¼ ê°–ì¶”ê²Œ ë˜ì—ˆìœ¼ë©°, CUDA í™˜ê²½ì—ì„œì˜ ë‹¤ì–‘í•œ ìµœì í™” ê¸°ë²•ì„ ì²´ë“í–ˆìŠµë‹ˆë‹¤.


### [QaaD (query-as-a-data)](https://dl.acm.org/doi/abs/10.1145/3589279)

I participated in the development of a system leveraging Apache Spark to efficiently process massive volumes of small queries. Diverging from the traditional Spark approach of splitting a single query into multiple sub-queries, I proposed and implemented a reverse strategy that merges numerous small queries into a single large-scale query for batch processing. Although I concluded my involvement prior to the paper publication to focus on GPU acceleration research, I was deeply involved in implementing the core logic and gained valuable experience in designing large-scale distributed processing systems.

Apache Sparkë¥¼ í™œìš©í•˜ì—¬ ëŒ€ëŸ‰ì˜ ì†Œê·œëª¨ ì§ˆì˜(Small Queries)ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ëŠ” ì‹œìŠ¤í…œ ê°œë°œì— ì°¸ì—¬í–ˆìŠµë‹ˆë‹¤. ê¸°ì¡´ Sparkê°€ í•˜ë‚˜ì˜ ì§ˆì˜ë¥¼ ì—¬ëŸ¬ í•˜ìœ„ ì‘ì—…(Sub-query)ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ë³‘ë ¬ ì²˜ë¦¬í•˜ëŠ” ê²ƒê³¼ ë‹¬ë¦¬, ë³¸ í”„ë¡œì íŠ¸ì—ì„œëŠ” ì—­ë°œìƒìœ¼ë¡œ ìˆ˜ë§ì€ ì†Œê·œëª¨ ì§ˆì˜ë¥¼ í•˜ë‚˜ì˜ ê±°ëŒ€ ì§ˆì˜ë¡œ ë³‘í•©í•˜ì—¬ Sparkì—ì„œ ì¼ê´„ ì²˜ë¦¬í•˜ëŠ” ê¸°ë²•ì„ ì œì•ˆí–ˆìŠµë‹ˆë‹¤. ë³¸ í”„ë¡œì íŠ¸ì˜ í•µì‹¬ ë¡œì§ êµ¬í˜„ì— ê¹Šì´ ê´€ì—¬í–ˆìœ¼ë‚˜, ì´í›„ GPU ê°€ì† ì—°êµ¬ì— ì§‘ì¤‘í•˜ê¸° ìœ„í•´ ë…¼ë¬¸ ì§‘í•„ ë‹¨ê³„ ì´ì „ì— í”„ë¡œì íŠ¸ë¥¼ ë§ˆë¬´ë¦¬í•˜ì—¬ ì €ì ëª©ë¡ì—ëŠ” í¬í•¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ëŒ€ê·œëª¨ ë¶„ì‚° ì²˜ë¦¬ ì‹œìŠ¤í…œì„ ì„¤ê³„í•˜ëŠ” ê·€ì¤‘í•œ ê²½í—˜ì„ ìŒ“ì•˜ìŠµë‹ˆë‹¤.

### Product Search Engine

I developed a distributed crawling framework that periodically collects product information from global e-commerce platforms and normalizes it into user-desired formats. Through this project, I gained practical experience in addressing challenges such as anti-crawling mechanisms and designing large-scale crawling architectures, while also acquiring background knowledge in Entity Matching technology to link data from disparate sources. I possess the technical insight that integrating modern LLM technologies into this workflow could have significantly enhanced data transformation and matching efficiency.

ê¸€ë¡œë²Œ ì „ììƒê±°ë˜ ì—…ì²´ë“¤ì˜ ìƒí’ˆ ì •ë³´ë¥¼ ì£¼ê¸°ì ìœ¼ë¡œ ìˆ˜ì§‘í•˜ê³ , ì´ë¥¼ ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ë°ì´í„° í¬ë§·ìœ¼ë¡œ ì •ê·œí™”í•˜ì—¬ ì €ì¥í•˜ëŠ” ë¶„ì‚° í¬ë¡¤ë§ í”„ë ˆì„ì›Œí¬ë¥¼ ê°œë°œí–ˆìŠµë‹ˆë‹¤. ì´ ê³¼ì •ì—ì„œ í¬ë¡¤ë§ ë°©ì§€(Anti-crawling) ëŒ€ì‘, ëŒ€ê·œëª¨ í¬ë¡¤ë§ ì•„í‚¤í…ì²˜ ì„¤ê³„ ë“± ì‹¤ë¬´ì ì¸ ì´ìŠˆë“¤ì„ í•´ê²°í•˜ë©° í’ë¶€í•œ ê²½í—˜ì„ ìŒ“ì•˜ìŠµë‹ˆë‹¤. ë˜í•œ, ì„œë¡œ ë‹¤ë¥¸ ì¶œì²˜ì˜ ë°ì´í„°ë¥¼ ì—°ê²°í•˜ëŠ” Entity Matching ê¸°ìˆ ì— ëŒ€í•œ ë°°ê²½ ì§€ì‹ë„ ìŠµë“í–ˆìŠµë‹ˆë‹¤. ìµœê·¼ì˜ ë°œì „ëœ LLM ê¸°ìˆ ì„ ë‹¹ì‹œ í”„ë¡œì íŠ¸ì— ì ‘ëª©í–ˆë‹¤ë©´ ë°ì´í„° ë³€í™˜ ë° ë§¤ì¹­ íš¨ìœ¨ì„ íšê¸°ì ìœ¼ë¡œ ë†’ì¼ ìˆ˜ ìˆì—ˆì„ ê²ƒì´ë¼ëŠ” ê¸°ìˆ ì  ì¸ì‚¬ì´íŠ¸ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.

### [iturbograph](https://dl.acm.org/doi/abs/10.1145/3448016.3457243)

I participated in the development of a distributed and parallel processing system that supports incremental updates for the results of massive graph analysis queries (e.g., PageRank, SCC, WCC, SSSP). My primary role involved conducting experiments and analyzing competing systems, which allowed me to build extensive experience in distributed and parallel computing environments utilizing technologies such as Rust and MPI.

ì´ˆê±°ëŒ€ ê·¸ë˜í”„ ë¶„ì„ ì§ˆì˜(i.e., PageRank, SCC, WCC, SSSP) ê²°ê³¼ì— ëŒ€í•œ ì ì§„ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë¥¼ ì§€ì›í•˜ëŠ” ë¶„ì‚°/ë³‘ë ¬ ì²˜ë¦¬ ì‹œìŠ¤í…œ ê°œë°œì— ì°¸ì—¬í•˜ì˜€ìŠµë‹ˆë‹¤. ê²½ìŸ ì‹œìŠ¤í…œì— ëŒ€í•œ ì‹¤í—˜ ë° ë¶„ì„ì„ ë§¡ì•˜ìœ¼ë©° ì´ë¥¼ í†µí•´ ë¶„ì‚°/ë³‘ë ¬ í™˜ê²½(e.g., Rust, MPI)ì— ëŒ€í•œ ê²½í—˜ì„ ìŒ“ì„ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.

### [G-CARE](https://www.researchgate.net/profile/Sourav-S-Bhowmick/publication/341750604_G-CARE_A_Framework_for_Performance_Benchmarking_of_Cardinality_Estimation_Techniques_for_Subgraph_Matching/links/5ee45f61a6fdcc73be780998/G-CARE-A-Framework-for-Performance-Benchmarking-of-Cardinality-Estimation-Techniques-for-Subgraph-Matching.pdf)

"I participated in a project proposing a benchmark for cardinality estimation techniques in subgraph matching and analyzing state-of-the-art (SOTA) methodologies. My main contribution was extending the query optimizer of RDF-3X, an RDF database, to support SOTA methods as plug-in modules. This experience provided me with deep insights into the fields of query optimization and cardinality estimation.

ê·¸ë˜í”„ ë¶„ì„ ì§ˆì˜ ì¤‘ í•˜ë‚˜ì¸ ì„œë¸Œê·¸ë˜í”„ ë§¤ì¹­ ê²°ê³¼ì˜ ìˆ˜ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë°©ë²•ë¡ ë“¤ì„ ìœ„í•œ ë²¤ì¹˜ë§ˆí¬ë¥¼ ì œì•ˆí•˜ê³  ë‹¹ì‹œ SOTA ë°©ë²•ë“¤ì„ ë¶„ì„í•œ í”„ë¡œì íŠ¸ì— ì°¸ê°€í•˜ì˜€ìŠµë‹ˆë‹¤. ì£¼ìš” ì—…ë¬´ëŠ” RDF ë°ì´í„°ë² ì´ìŠ¤ ì¤‘ í•˜ë‚˜ì¸ RDF-3Xì˜ query optimizerë¥¼ í™•ì¥í•˜ì—¬ SOTA ë°©ë²•ë“¤ì„ í”ŒëŸ¬ê·¸ì¸ í˜•íƒœë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ í•˜ëŠ” ê²ƒì´ì—ˆìœ¼ë©°, ì´ë¥¼ í†µí•´ query optimizerì™€ cardinality estmation ë¶„ì•¼ì— ëŒ€í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ìŒ“ì„ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.

<!-- ### SIMD-based B+-tree
TBD -->

---

## ğŸ“ Education  

- **Ph.D.** in Computer Science and Engineering, POSTECH, South Korea, (2018.2-2025.8)  
  Advisor: Wook-Shin Han
- **B.S.** in Industrial and Management Engineering and Computer Science and Engineering, POSTECH, South Korea, (2011.3-2018.2)

---

## ğŸ’¼ Employment

- **Researcher**, Ceres Technologies, Republic of Korea, (2025.1 - Present)  
  - High frequency trading
  - LLM serving (vLLM, Kubernetes, etc.), LLM fine-tuning
  - LLM inference optimization (caching, scheduling)
  - RAG system
- **Intern**, Exem, Republic of Korea, (2016. 6 - 2016. 8)

---

## ğŸ“š Publications

### 2025

**The Effect of Scheduling and Preemption on the Efficiency of LLM Inference Serving**  
*Kyoungmin Kim, Jiacheng Li, **Kijae Hong**, and Anastasia Ailamaki*  
arXiv:2411.07447, 2025 (Under Review at VLDB 2026)

**Large Language Models for Semantic Join: A Comprehensive Survey**  
***Kijae Hong*** *and Yeonsu Park*  
*IEEE Access*, 2025

**Design and Evaluation of a GPU-Accelerated SQL Query Engine for Large-Scale Analytics**  
***Kijae Hong***  
Ph.D. Dissertation, POSTECH, 2025

**[Themis: A GPU-accelerated Relational Query Execution Engine](https://www.vldb.org/pvldb/vol18/p426-han.pdf)**  
***Kijae Hong***, *Kyoungmin Kim, Young-Koo Lee, Yang-Sae Moon, Sourav S Bhowmick, and Wook-Shin Han*  
*Very Large Data Bases Conference (VLDB)*, 2025 â­

### 2022

**Survey on the GPU-Based Graph Analytics Methods**  
***Kijae Hong***, *Jinho Ko, Taesung Lee, and Wook-Shin Han*  
*Korea Computer Congress (KCC)*, 2022

**Performance Analysis of Property Graph Queries on Graph and Relational Databases**  
*Jinho Ko, Taesung Lee, **Kijae Hong**, and Wook-Shin Han*  
*Korea Computer Congress (KCC)*, 2022

### 2021

**[iTurboGraph: Scaling and Automating Incremental Graph Analytics](https://dl.acm.org/doi/abs/10.1145/3448016.3457243)**  
*Seongyun Ko, Taesung Lee, **Kijae Hong**, Wonseok Lee, In Seo, Jiwon Seo, and Wook-Shin Han*  
*ACM International Conference on Management of Data (SIGMOD)*, 2021 â­

**A Study on Property Graph Partitioning for Graph Analytic Query Processing in Distributed Environment**  
*Jinho Ko, **Kijae Hong**, Taesung Lee, Jeong-Hoon Lee, and Wook-Shin Han*  
*Korea Computer Congress (KCC)*, 2021

**Graph Analytics Query Acceleration Using Filtering Techniques in Page-Based Dynamic Graph Storage**  
*Taesung Lee, **Kijae Hong**, Jeong-Hoon Lee, and Wook-Shin Han*  
*Korea Computer Congress (KCC)*, 2021

### 2020

**[G-CARE: A Framework for Performance Benchmarking of Cardinality Estimation Techniques for Subgraph Matching](https://www.researchgate.net/profile/Sourav-S-Bhowmick/publication/341750604_G-CARE_A_Framework_for_Performance_Benchmarking_of_Cardinality_Estimation_Techniques_for_Subgraph_Matching/links/5ee45f61a6fdcc73be780998/G-CARE-A-Framework-for-Performance-Benchmarking-of-Cardinality-Estimation-Techniques-for-Subgraph-Matching.pdf)**  
*Yeonsu Park, Seongyun Ko, Sourav S. Bhowmick, Kyoungmin Kim, **Kijae Hong**, and Wook-Shin Han*  
*ACM International Conference on Management of Data (SIGMOD)*, 2020 â­

### 2018

**A Survey on Top-down and Bottom-up Inductive Logic Programming Methods**  
*In Seo, Jeong-Hoon Lee, Kyoungmin Kim, **Kijae Hong**, Byunghoon So, and Wook-Shin Han*  
*Korea Computer Congress (KCC)*, 2018

---

### ğŸ”– Patents

**GPU-Based Query Processing Acceleration Method and Computing System**  
*Wook-Shin Han, **Kijae Hong**, Taesung Lee, and Kyoungmin Kim*  
U.S. Patent Application No. 19/144,304 (Filed: Jul. 2025)

**METHOD FOR GENERATING CONTENTS BASED ON TEMPLATE**  
***Kijae Hong***  
Korean Patent Registration No. 10-2025-0068845 (Filed: May. 2025)

**METHOD FOR OPTIMIZING INFERENCE OF LANGUAGE MODEL**  
***Kijae Hong***  
Korean Patent Registration No. 10-2025-0066840 (Filed: May. 2025)

**Method for Summarizing Document Using Large Language Model**  
*Inhyeok Na, **Kijae Hong**, and Jaehyun Lim*  
Korean Patent Registration No. 10-2025-0084553 (Published: Jun. 2025)

**Method for Retrieving Document Related to Natural Language Query**  
*Inhyeok Na, **Kijae Hong**, Jaehyun Lim, and Haechan Lee*  
Korean Patent Registration No. 10-2815043-0000 (Registered: May. 2025)

**Method and Computing System for Acceleration of Processing Queries Based on GPU**  
*Wook-Shin Han, Taesung Lee, Kyungmin Kim, and **Kijae Hong***  
Korean Patent Registration No. 10-2649076-0000 (Registered: Mar. 2024)

**Distributed Processing System and Method for Processing Data**  
*Wook-Shin Han, Yeonsu Park, and **Kijae Hong***  
Korean Patent Registration No. 10-2024-0026045 (Published: Feb. 2024)

**A Method for Mapping a Natural Language Sentence to an SQL Query**  
*Wook-Shin Han, Hyunji Kim, Jungho Jo, Yukyung Lee, and **Kijae Hong***  
Korean Patent Registration No. 10-2149701-0000 (Registered: Aug. 2020)

---

## ğŸ¤ Academic Talks

- Vector-Based Search for Semantic Join, Kangwon National University, (Nov. 2025)
- Retrieval-Augmented Generation and Vector Databases, Chung-ang University, (Nov. 2024)

---

## ğŸ‘¨â€ğŸ« Teaching Experience

- Big Data Course, Samsung, (2018-2019) - TA
- Database Course, POSTECH, (2018-2019) - TA

---

## ğŸ› ï¸ Skills

- **Programming languages**: C++, Python, Java, JavaScript, CUDA
- **Development frameworks**: Flutter, React, Django
- **Infra**: Kubernetes, Firebase, AWS
- **DB+AI**: vLLM, LLMCache, etc.

---

## ğŸ”— Other Links

- Wook-Shin Han, Professor, POSTECH - wshan@dblab.postech.ac.kr
- Yang-Sae Moon, Professor, Kangwon National University - ysmoon@kangwon.ac.kr
- Sourav S. Bhowmick, Associate Professor, Nanyang Technological University - assourav@ntu.edu.sg
- Young-Koo Lee, Professor, Kyung Hee University - yklee@khu.ac.kr